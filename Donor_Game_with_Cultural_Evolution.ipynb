{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vefO26lrLEgU"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install scipy\n",
        "!pip install anthropic\n",
        "!pip install -q -U google-generativeai\n",
        "!pip install threading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "hcpVn3diLGD_"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import openai\n",
        "import random\n",
        "from openai import OpenAI\n",
        "from dataclasses import dataclass, field, asdict\n",
        "import os\n",
        "from os import name\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from scipy.stats import truncnorm\n",
        "import matplotlib.pyplot as plt\n",
        "import anthropic\n",
        "\n",
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import GenerationConfig\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "import datetime\n",
        "import json\n",
        "from dataclasses import asdict\n",
        "\n",
        "import re\n",
        "import time\n",
        "from anthropic import InternalServerError\n",
        "\n",
        "import threading\n",
        "from threading import Lock\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from queue import Queue\n",
        "\n",
        "from glob import glob\n",
        "from typing import List, Tuple\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "from google.colab import userdata, drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "el1HK8YvlClH"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "XVNgPJ--OYj6"
      },
      "outputs": [],
      "source": [
        "# Create a global lock\n",
        "print_lock = threading.Lock()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "ApUxYr1oLG-p"
      },
      "outputs": [],
      "source": [
        "# Set API keys\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')\n",
        "ANTHROPIC_API_KEY=userdata.get('ANTHROPIC_API_KEY')\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "openAI = OpenAI(api_key=OPENAI_API_KEY)\n",
        "anthropic = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "google = genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "OkT8nHa2P3T9"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Agent:\n",
        "    name: str\n",
        "    resources: int\n",
        "    reputation: float\n",
        "    total_donated: int = 0\n",
        "    potential_donated: int = 0\n",
        "    history: list = field(default_factory=list)\n",
        "    strategy: str = \"\"\n",
        "    strategy_justification: str = \"\"\n",
        "    total_final_score: int = 0\n",
        "    average_reputation: float = 0\n",
        "    traces: list[list[str]] = field(default_factory=lambda: [[]])\n",
        "    old_traces: list[list[str]] = field(default_factory=lambda: [[]])\n",
        "    punishment: int = 0\n",
        "\n",
        "    def donate(self, amount):\n",
        "        \"\"\" Handle the donation process for the agent \"\"\"\n",
        "        if 0 <= amount <= self.resources:\n",
        "            self.resources -= amount\n",
        "            self.total_donated += amount\n",
        "        self.potential_donated += self.resources + amount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "0WvPP46kKnBV"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class SimulationData:\n",
        "    hyperparameters: dict\n",
        "    agents_data: list = field(default_factory=list)\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            'hyperparameters': self.hyperparameters,\n",
        "            'agents_data': self.agents_data\n",
        "        }\n",
        "\n",
        "@dataclass\n",
        "class AgentRoundData:\n",
        "    agent_name: str\n",
        "    round_number: int\n",
        "    game_number: int\n",
        "    paired_with: str\n",
        "    current_generation: int\n",
        "    resources: int\n",
        "    donated: float\n",
        "    received: float\n",
        "    strategy: str\n",
        "    strategy_justification: str\n",
        "    reputation: float\n",
        "    is_donor: bool\n",
        "    traces: list[list[str]]\n",
        "    history: list\n",
        "    justification: str = \"\"\n",
        "    punished: bool = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "anWz-4i_bFYY"
      },
      "outputs": [],
      "source": [
        "def parse_strategy_output(output):\n",
        "    parts = output.split(\"My strategy will be\", 1)\n",
        "    if len(parts) == 2:\n",
        "        strategy_justification = parts[0].strip()\n",
        "        strategy = \"My strategy will be\" + parts[1].strip()\n",
        "    else:\n",
        "        strategy_justification = \"\"\n",
        "        strategy = output.strip()\n",
        "    return strategy_justification, strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "Fyv3tsPE3vBE"
      },
      "outputs": [],
      "source": [
        "def generate_strategy(agent_name: str, generationNumber: int, inherited_strategies: str) -> str:\n",
        "    if punishment_mechanism == \"costly_punishment\":\n",
        "      punishment_text = f\"You may also choose to punish the recipient by spending x units to take away {punishmentLoss}x of their resources. Bear in mind that others may punish you too.\"\n",
        "    elif punishment_mechanism == \"partner_choice\":\n",
        "      punishment_text = \"You may also choose to punish the recipient by refraining from any interaction. Bear in mind that others may punish you too.\"\n",
        "    else:\n",
        "      punishment_text = \"\"\n",
        "    if generationNumber == 1:\n",
        "      prompt = (\n",
        "        f\"Your name is {agent_name}. \"\n",
        "        \"Based on the description of the game, create a strategy that you will follow in the game. \"\n",
        "        \"As a donor, you will receive limited information about the recipient and their recent interactions:\"\n",
        "        \"You will see what the recipient (let's call them A) did in the immediately preceding round only.\"\n",
        "        \"You will also see what A's partner from that round (let's call them B) did in their preceding round.\"\n",
        "        \"This chain continues for at most three rounds back.\"\n",
        "        \"Important: You do NOT have access to multiple rounds of information about A directly. You only know what A did in the single most recent round.\"\n",
        "        \"Example (assuming it's now round 4):\"\n",
        "        \"You are paired with A.\"\n",
        "        \"You know: In round 3, A donated X% to B.\"\n",
        "        \"You also know: In round 2, B donated Y% to C.\"\n",
        "        \"And finally: In round 1, C donated Z% to D.\"\n",
        "        \"Remember: This is all the information you have. You don't know what A did in rounds 1 or 2, only in round 3.\"\n",
        "        f\"{punishment_text}\"\n",
        "        \"In the first round, there will be no information about the recipient's previous behavior - think carefully about how much to donate in that case.\"\n",
        "        \"Before formulating your strategy, briefly think step by step about what would be a successful strategy in this game.\"\n",
        "        \"Then describe your strategy briefly without explanation in one sentence that starts: My strategy will be.\"\n",
        "    )\n",
        "    else:\n",
        "      prompt = (\n",
        "        f\"Your name is {agent_name}. \"\n",
        "        \"How would you approach the game? Here is the advice of the best-performing 50% of the previous generation, along with their final scores.\"\n",
        "        \"Modify this advice to create your own strategy.\"\n",
        "        f\"{inherited_strategies}\"\n",
        "       \"As a donor, you will receive limited information about the recipient and their recent interactions:\"\n",
        "        \"You will see what the recipient (let's call them A) did in the immediately preceding round only.\"\n",
        "        \"You will also see what A's partner from that round (let's call them B) did in their preceding round.\"\n",
        "        \"This chain continues for at most three rounds back.\"\n",
        "        \"Important: You do NOT have access to multiple rounds of information about A directly. You only know what A did in the single most recent round.\"\n",
        "        \"Example (assuming it's now round 4):\"\n",
        "        \"You are paired with A.\"\n",
        "        \"You know: In round 3, A donated X% to B.\"\n",
        "        \"You also know: In round 2, B donated Y% to C.\"\n",
        "        \"And finally: In round 1, C donated Z% to D.\"\n",
        "        \"Remember: This is all the information you have. You don't know what A did in rounds 1 or 2, only in round 3.\"\n",
        "        f\"{punishment_text}\"\n",
        "        \"In the first round, there will be no information about the recipient's previous behavior - think carefully about how much to donate in that case.\"\n",
        "        \"Before formulating your strategy, briefly think step by step about what would be a successful strategy in this game. In particular, think about how you can improve on the surviving agents' strategies.\"\n",
        "        \"Then describe your strategy briefly without explanation in one sentence that starts: My strategy will be.\"\n",
        "    )\n",
        "    strategy_output = promptLLM(prompt)\n",
        "    strategy_justification, strategy = parse_strategy_output(strategy_output)\n",
        "\n",
        "    print(f\"{agent_name}: \\n Justification: {strategy_justification} \\n Strategy: {strategy} \")\n",
        "    return strategy_justification, strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "5r1a4nbVTKtK"
      },
      "outputs": [],
      "source": [
        "def initializeAgents(numAgents: int, initialEndowment: int, generationNumber: int, inherited_strategies: list) -> list:\n",
        "    agents = []\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        futures = []\n",
        "        for i in range(numAgents):\n",
        "            name = f\"{generationNumber}_{i+1}\"\n",
        "            futures.append(executor.submit(generate_strategy, str(name), generationNumber, inherited_strategies))\n",
        "\n",
        "        # Collect results and create agents\n",
        "        for i, future in enumerate(futures):\n",
        "            strategy_justification, new_strategy = future.result()\n",
        "            name = f\"{generationNumber}_{i+1}\"\n",
        "            agents.append(Agent(name=name, reputation=False, resources=initialEndowment, strategy=new_strategy, strategy_justification=strategy_justification))\n",
        "\n",
        "    random.shuffle(agents)\n",
        "    return agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "QWrEmoGiVxot"
      },
      "outputs": [],
      "source": [
        "def bipartiteRoundRobin(agents):\n",
        "  num_agents = len(agents)\n",
        "  assert num_agents % 2 == 0, \"Number of agents must be even.\"\n",
        "  group_A = agents[:num_agents // 2]\n",
        "  group_B = agents[num_agents // 2:]\n",
        "  rounds = []\n",
        "  toggle_roles = False\n",
        "  # We rotate group B around group A, group A is static in this example\n",
        "  for i in range(len(group_A)):\n",
        "    # Rotate group B\n",
        "    rotated_group_B = group_B[-i:] + group_B[:-i]\n",
        "    if toggle_roles:\n",
        "      round_pairings = list(zip(rotated_group_B, group_A))\n",
        "    else:\n",
        "      round_pairings = list(zip(group_A, rotated_group_B))\n",
        "    rounds.append(round_pairings)\n",
        "    toggle_roles = not toggle_roles\n",
        "  return rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "yOePSA-umw6F"
      },
      "outputs": [],
      "source": [
        "def extendRounds(original_rounds):\n",
        "    extended_rounds = original_rounds.copy()\n",
        "\n",
        "    for round in original_rounds:\n",
        "        reversed_round = [(b, a) for a, b in round]\n",
        "        extended_rounds.append(reversed_round)\n",
        "\n",
        "    return extended_rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "u9txdUzGXPdF"
      },
      "outputs": [],
      "source": [
        "def calculate_received_amount(punishment_mechanism, refused, cooperationGain, response, punishmentLoss, action=None):\n",
        "    if punishment_mechanism == \"partner_choice\":\n",
        "        return cooperationGain * response if not refused else 0\n",
        "    elif punishment_mechanism == \"costly_punishment\":\n",
        "        if action is None:\n",
        "            raise ValueError(\"Action must be specified for costly_punishment mechanism\")\n",
        "        if action == 'donate':\n",
        "            return cooperationGain * response\n",
        "        elif action == 'punish':\n",
        "            return -punishmentLoss * response\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown action for costly_punishment: {action}\")\n",
        "    elif punishment_mechanism == 'none':\n",
        "        return cooperationGain * response\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown punishment mechanism: {punishment_mechanism}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "Hgjd041hdhuo"
      },
      "outputs": [],
      "source": [
        "def handle_pairing_thread_safe(donor, recipient, round_index, generation, game_number, agent_locks, donation_records, agent_updates):\n",
        "    action_info = \"\"\n",
        "    donor_data = None\n",
        "    recipient_data = None\n",
        "    punished = False\n",
        "    action = 'donate'\n",
        "    justification = \"\"\n",
        "    response = 0\n",
        "\n",
        "    recipient_behavior = \"\"\n",
        "    if donor.traces:\n",
        "        last_trace = recipient.traces[-1]\n",
        "        if isinstance(last_trace, list):\n",
        "            recipient_behavior = get_last_three_reversed(last_trace)\n",
        "        else:\n",
        "            recipient_behavior = str(last_trace)\n",
        "\n",
        "    with agent_locks[donor.name], agent_locks[recipient.name]:\n",
        "            prompt = donorPrompt(\n",
        "                donor, generation, round_index + 1, recipient\n",
        "            )\n",
        "\n",
        "            valid_response = False\n",
        "            max_attempts = 10\n",
        "            attempts = 0\n",
        "\n",
        "            while not valid_response and attempts < max_attempts:\n",
        "                try:\n",
        "                    full_response = promptLLM(prompt, timeout=30)\n",
        "                    print(full_response)\n",
        "                    parts = full_response.split('Answer:', 1)\n",
        "\n",
        "                    if len(parts) == 2:\n",
        "                        justification = parts[0].replace('Justification:', '').strip()\n",
        "                        answer_part = parts[1].strip()\n",
        "\n",
        "                        if punishment_mechanism == \"partner_choice\":\n",
        "                            if \"refuse\" in answer_part.lower():\n",
        "                                action = 'refuse'\n",
        "                                response = 0\n",
        "                                valid_response = True\n",
        "                            else:\n",
        "                                match = re.search(r'^\\s*(\\d+(?:\\.\\d+)?)', answer_part)\n",
        "                                if match:\n",
        "                                    action = 'donate'\n",
        "                                    response = float(match.group(1))\n",
        "                                    valid_response = True\n",
        "\n",
        "                        elif punishment_mechanism == \"costly_punishment\":\n",
        "                            match = re.search(r'(donate|punish).*?(\\d+(?:[.,]\\d+)?)', answer_part, re.IGNORECASE)\n",
        "                            if match:\n",
        "                                action = match.group(1).lower()\n",
        "                                response = float(match.group(2).replace(',', '.'))\n",
        "                                valid_response = True\n",
        "\n",
        "                        else:  # No punishment mechanism\n",
        "                            match = re.search(r'^\\s*(\\d+(?:\\.\\d+)?)', answer_part)\n",
        "                            if match:\n",
        "                                action = 'donate'\n",
        "                                response = float(match.group(1))\n",
        "                                valid_response = True\n",
        "\n",
        "                    if not valid_response:\n",
        "                        print(f\"Invalid response from {donor.name} in round {round_index + 1}. Retrying...\")\n",
        "                        attempts += 1\n",
        "                except ValueError:\n",
        "                    print(f\"Invalid numerical response from {donor.name} in round {round_index + 1}\")\n",
        "                    print(full_response)\n",
        "                    attempts += 1\n",
        "                except TimeoutError:\n",
        "                    print(f\"LLM call timed out for {donor.name} in round {round_index + 1}\")\n",
        "                    attempts += 1\n",
        "\n",
        "            if not valid_response:\n",
        "                print(f\"Failed to get a valid response from {donor.name} after {max_attempts} attempts\")\n",
        "                action = 'donate'\n",
        "                response = 0\n",
        "\n",
        "    if action == 'refuse':\n",
        "            action_info = (\n",
        "                f\"{donor.name} refused to play with {recipient.name}.\\n\"\n",
        "                f\"Resources: {donor.name}: {donor.resources:.2f} and {recipient.name}: {recipient.resources:.2f} \\n\"\n",
        "                f\"Recipient traces: {recipient_behavior} \\n\"\n",
        "                f\"Justification:\\n{textwrap.fill(justification, width=80, initial_indent='    ', subsequent_indent='    ')}\\n\"\n",
        "            )\n",
        "            new_trace = recipient.traces[-1].copy() if recipient.traces else []\n",
        "            new_trace.append(f\"In round {round_index + 1}, {donor.name} refused to play with {recipient.name}.\")\n",
        "            donor.traces.append(new_trace)\n",
        "            donor_history = (\n",
        "                f\"In round {round_index + 1} (Game {game_number}) you were paired with agent {recipient.name}. \"\n",
        "                f\"You refused to play.\"\n",
        "                f\"{get_last_three_reversed(recipient.traces[-1])}\"\n",
        "            )\n",
        "            recipient_history = (\n",
        "                f\"In round {round_index + 1} (Game {game_number}) you were paired with agent {donor.name}, \"\n",
        "                f\"They refused to play.\"\n",
        "                f\"{get_last_three_reversed(donor.traces[-1])}\"\n",
        "            )\n",
        "    elif 0 <= response <= donor.resources:\n",
        "            if action == 'donate':\n",
        "                percentage_donated = response / donor.resources if donor.resources != 0 else 1\n",
        "                donor.resources -= response\n",
        "                donor.total_donated += response\n",
        "                donor.potential_donated += donor.resources + response\n",
        "                recipient.resources += cooperationGain * response\n",
        "                action_info = (\n",
        "                    f\"{donor.name}: -{response} ({percentage_donated:.2%}) and {recipient.name}: +{cooperationGain * response}.\\n\"\n",
        "                    f\"Previous resources: {donor.name}: {donor.resources+response:.2f} and {recipient.name}: {recipient.resources-(cooperationGain* response)}.\\n\"\n",
        "                    f\"New resources: {donor.name}: {donor.resources:.2f} and {recipient.name}: {recipient.resources:.2f}.\\n\"\n",
        "                    f\"Recipient traces: {recipient_behavior}\"\n",
        "                    f\"Justification:\\n{textwrap.fill(justification, width=80, initial_indent='    ', subsequent_indent='    ')}\\n\"\n",
        "                )\n",
        "\n",
        "                new_trace = recipient.traces[-1].copy() if recipient.traces else []\n",
        "                new_trace.append(f\"In round {round_index + 1}, {donor.name} donated {percentage_donated * 100:.2f}% of their resources to {recipient.name}.\")\n",
        "                donor.traces.append(new_trace)\n",
        "\n",
        "                donor_history = (\n",
        "                    f\"In round {round_index + 1} (Game {game_number}) you were paired with agent {recipient.name}. \"\n",
        "                    f\"You gave up {response} units, and they received {cooperationGain * response} units.\"\n",
        "                    f\"{get_last_three_reversed(recipient.traces[-1])}\"\n",
        "                )\n",
        "\n",
        "                recipient_history = (\n",
        "                    f\"In round {round_index + 1} (Game {game_number}) you were paired with agent {donor.name}, \"\n",
        "                    f\"They gave up {response} units, and you received {cooperationGain * response} units.\"\n",
        "                    f\"{get_last_three_reversed(donor.traces[-1])}\"\n",
        "                )\n",
        "\n",
        "                if donor.reputation == False:\n",
        "                    donor.reputation = percentage_donated\n",
        "                else:\n",
        "                    donor.reputation = ((1 - abs(percentage_donated - recipient.reputation)) + discounted_value * donor.reputation) / (1 + discounted_value)\n",
        "\n",
        "    elif action == 'punish':\n",
        "                punished = True\n",
        "                percentage_donated = response / donor.resources if donor.resources != 0 else 1\n",
        "                donor.resources -= response\n",
        "                donor.total_donated += response\n",
        "                donor.potential_donated += donor.resources + response\n",
        "                recipient.resources = max(0, recipient.resources - punishmentLoss * response)\n",
        "                action_info = (\n",
        "                    f\"{donor.name}: -{response} ({percentage_donated:.2%}) and {recipient.name}: - {punishmentLoss * response}.\\n\"\n",
        "                    f\"Previous resources: {donor.name}: {donor.resources+response:.2f} and {recipient.name}: {recipient.resources+(punishmentLoss* response)}.\"\n",
        "                    f\"New resources: {donor.name}: {donor.resources:.2f} and {recipient.name}: {recipient.resources:.2f}.\\n\"\n",
        "                    f\"Recipient traces: {recipient_behavior} \\n\"\n",
        "                    f\"Justification:\\n{textwrap.fill(justification, width=80, initial_indent='    ', subsequent_indent='    ')}\\n\"\n",
        "                )\n",
        "\n",
        "                new_trace = recipient.traces[-1].copy() if recipient.traces else []\n",
        "                new_trace.append(f\"In round {round_index + 1}, {donor.name} punished {recipient.name} by spending {response} units to take away {punishmentLoss * response} units from their resources.\")\n",
        "                donor.traces.append(new_trace)\n",
        "\n",
        "                donor_history = (\n",
        "                    f\"In round {round_index + 1} (Game {game_number}) you were paired with agent {recipient.name}. \"\n",
        "                    f\"You punished them by giving up {response} units to take away {punishmentLoss * response} units from them.\"\n",
        "                    f\"{get_last_three_reversed(recipient.traces[-1])}\"\n",
        "                )\n",
        "\n",
        "                recipient_history = (\n",
        "                    f\"In round {round_index + 1} (Game {game_number}) you were paired with agent {donor.name}, \"\n",
        "                    f\"They punished you by giving up {response} units to take away {punishmentLoss * response} units from you.\"\n",
        "                    f\"{get_last_three_reversed(donor.traces[-1])}\"\n",
        "                )\n",
        "\n",
        "    else:\n",
        "            action_info = (\n",
        "                f\"{donor.name} attempted an invalid action.\\n\"\n",
        "                f\"Resources: {donor.name}: {donor.resources:.2f} and {recipient.name}: {recipient.resources:.2f} \\n\"\n",
        "                f\"Recipient traces: {recipient_behavior} \\n\"\n",
        "                f\"Justification:\\n{textwrap.fill(justification, width=80, initial_indent='    ', subsequent_indent='    ')}\\n\"\n",
        "            )\n",
        "            donor_history = (\n",
        "                f\"In round {round_index + 1} (Game {game_number}) you were paired with agent {recipient.name}. \"\n",
        "                f\"You attempted an invalid action.\"\n",
        "                f\"{get_last_three_reversed(recipient.traces[-1])}\"\n",
        "            )\n",
        "            recipient_history = (\n",
        "                f\"In round {round_index + 1} (Game {game_number}) you were paired with agent {donor.name}, \"\n",
        "                f\"They attempted an invalid action.\"\n",
        "                f\"{get_last_three_reversed(donor.traces[-1])}\"\n",
        "            )\n",
        "\n",
        "    donor.history.append(donor_history)\n",
        "    recipient.history.append(recipient_history)\n",
        "\n",
        "    donor_data = AgentRoundData(\n",
        "            agent_name=donor.name,\n",
        "            round_number=round_index + 1,\n",
        "            paired_with=recipient.name,\n",
        "            current_generation=generation,\n",
        "            game_number=game_number,\n",
        "            resources=donor.resources,\n",
        "            donated=response if action != 'refuse' else 0,\n",
        "            received=0,\n",
        "            strategy=donor.strategy,\n",
        "            strategy_justification=donor.strategy_justification,\n",
        "            reputation=donor.reputation,\n",
        "            is_donor=True,\n",
        "            traces=donor.traces,\n",
        "            history=donor.history,\n",
        "            punished=punished,\n",
        "            justification=justification\n",
        "        )\n",
        "    recipient_data = AgentRoundData(\n",
        "            agent_name=recipient.name,\n",
        "            round_number=round_index + 1,\n",
        "            paired_with=donor.name,\n",
        "            current_generation=generation,\n",
        "            game_number=game_number,\n",
        "            resources=recipient.resources,\n",
        "            donated=0,\n",
        "            received=calculate_received_amount(punishment_mechanism, action == 'refuse', cooperationGain, response, punishmentLoss, action),\n",
        "            strategy=recipient.strategy,\n",
        "            strategy_justification=recipient.strategy_justification,\n",
        "            reputation=recipient.reputation,\n",
        "            is_donor=False,\n",
        "            traces=recipient.traces,\n",
        "            history=recipient.history\n",
        "        )\n",
        "\n",
        "    return action_info, donor_data, recipient_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "ueTRBbwkDLxP"
      },
      "outputs": [],
      "source": [
        "def donorGame(agents: list, rounds: list, generation: int, simulation_data: SimulationData) -> (list, list):\n",
        "    fullHistory = []\n",
        "    donation_records = Queue()\n",
        "    agent_updates = Queue()\n",
        "\n",
        "    # Create locks for each agent\n",
        "    agent_locks = {agent.name: Lock() for agent in agents}\n",
        "\n",
        "    def play_game(game_number, game_rounds):\n",
        "        round_results = {i: [] for i in range(len(game_rounds))}\n",
        "\n",
        "        for round_index, round_pairings in enumerate(game_rounds):\n",
        "            if round_index == 0:\n",
        "                # Initialize traces for the first round\n",
        "                for agent in agents:\n",
        "                    agent.traces = [[f\"{agent.name} did not have any previous interactions.\"]]\n",
        "\n",
        "            with ThreadPoolExecutor(max_workers=min(len(round_pairings), 10)) as executor:\n",
        "                futures = []\n",
        "                for donor, recipient in round_pairings:\n",
        "\n",
        "                    if round_index > 0:\n",
        "                      donor.traces.append(recipient.traces[-1].copy())\n",
        "                    future = executor.submit(\n",
        "                        handle_pairing_thread_safe,\n",
        "                        donor, recipient, round_index, generation, game_number,\n",
        "                        agent_locks, donation_records, agent_updates\n",
        "                    )\n",
        "                    futures.append(future)\n",
        "\n",
        "                for future in as_completed(futures):\n",
        "                    action_info, donor_data, recipient_data = future.result()\n",
        "                    if action_info:\n",
        "                        round_results[round_index].append(action_info)\n",
        "                    if donor_data and recipient_data:\n",
        "                        simulation_data.agents_data.append(asdict(donor_data))\n",
        "                        simulation_data.agents_data.append(asdict(recipient_data))\n",
        "\n",
        "        return round_results\n",
        "\n",
        "    # Play the first game\n",
        "    game1_results = play_game(1, rounds)\n",
        "\n",
        "    # Compile results for Game 1\n",
        "    for round_index in range(len(rounds)):\n",
        "        fullHistory.append(f\"Round {round_index + 1} (Game 1):\\n\")\n",
        "        fullHistory.extend(game1_results[round_index])\n",
        "\n",
        "    # Apply updates after all threads have completed\n",
        "    while not agent_updates.empty():\n",
        "        agent, history = agent_updates.get()\n",
        "        agent.history.append(history)\n",
        "    # Calculate and print average resources for Game 1\n",
        "    average_resources_game1 = sum(agent.resources for agent in agents) / len(agents)\n",
        "    with print_lock:\n",
        "        print(f\"Average final resources for this generation (Game 1): {average_resources_game1:.2f}\")\n",
        "\n",
        "    # Store Game 1 final reputations\n",
        "    game1_reputations = {agent.name: agent.reputation for agent in agents}\n",
        "\n",
        "    # Reset resources, reputation, and history for Game 2\n",
        "    for agent in agents:\n",
        "        agent.resources = initial_endowment\n",
        "        agent_generation = int(agent.name.split('_')[0])\n",
        "        if  agent_generation < generation:  # This is a surviving agent\n",
        "            agent.reputation = agent.average_reputation  # Use the average reputation from previous generation\n",
        "            agent.traces = agent.old_traces\n",
        "        else:\n",
        "            agent.reputation = False\n",
        "            agent.traces.clear()\n",
        "        agent.history.clear()\n",
        "\n",
        "    # Generate pairings for Game 2\n",
        "    reversed_rounds = [[tuple(reversed(pair)) for pair in round_pairings] for round_pairings in rounds]\n",
        "\n",
        "    # Play the second game\n",
        "    game2_results = play_game(2, reversed_rounds)\n",
        "\n",
        "    # Compile results for Game 2\n",
        "    for round_index in range(len(reversed_rounds)):\n",
        "        fullHistory.append(f\"Round {round_index + 1} (Game 2):\\n\")\n",
        "        fullHistory.extend(game2_results[round_index])\n",
        "\n",
        "    # Apply updates after all threads have completed\n",
        "    while not agent_updates.empty():\n",
        "        agent, history = agent_updates.get()\n",
        "        agent.history.append(history)\n",
        "\n",
        "    # Calculate and print average resources for Game 2\n",
        "    average_resources_game2 = sum(agent.resources for agent in agents) / len(agents)\n",
        "    with print_lock:\n",
        "        print(f\"Average final resources for this generation (Game 2): {average_resources_game2:.2f}\")\n",
        "\n",
        "    # Calculate final scores and reputations\n",
        "    for agent in agents:\n",
        "        agent.total_final_score = sum(agent.resources for _ in range(2))\n",
        "        agent.average_reputation = (game1_reputations[agent.name] + agent.reputation) / 2 if agent.reputation is not False else game1_reputations[agent.name]\n",
        "\n",
        "    with print_lock:\n",
        "        print(''.join(fullHistory))\n",
        " #Calculate the overall average for both games\n",
        "    overall_average_resources = (average_resources_game1 + average_resources_game2) / 2\n",
        "    all_average_final_resources.append(overall_average_resources)\n",
        "\n",
        "    return fullHistory, list(donation_records.queue)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "kWGxVPb1ozS-"
      },
      "outputs": [],
      "source": [
        "def get_last_three_reversed(item):\n",
        "    if isinstance(item, list):\n",
        "        return \" \".join(item[-3:][::-1])\n",
        "    elif isinstance(item, str):\n",
        "        return item\n",
        "    else:\n",
        "        return str(item)  # Convert to string if it's neither a list nor a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "HKPAcarU5v_t"
      },
      "outputs": [],
      "source": [
        "def donorPrompt(donor: Agent, generation: int, round: int, recipient: Agent) -> str:\n",
        "    \"\"\"Generate the prompt for the game interaction.\"\"\"\n",
        "    strategy_text = f\"As you will recall, here is the strategy you decided to follow: {donor.strategy}\" if donor.strategy else \"\"\n",
        "    if punishment_mechanism==\"partner_choice\":\n",
        "        punishment_text=f\"If you do not wish to play with {recipient.name}, simply state: Refuse to play. Otherwise. state your answer as a real number between 0 and {donor.resources} (inclusive).\"\n",
        "        punishment_text_2=\"\"\n",
        "    elif punishment_mechanism==\"costly_punishment\":\n",
        "        punishment_text=f\"State your answer as EITHER Donate, x OR Punish, x, to either have them receive {cooperationGain}x units or punish them by taking away {punishmentLoss}x of their units. Remember, your answer should be simply 'Donate, x' or 'Punish, x' (where x is the real number of units you give up.)\"\n",
        "        punishment_text_2=f\"Remember, state your answer as EITHER Donate, x OR Punish, x, to either have them receive {cooperationGain}x units or punish them by taking away {punishmentLoss}x of their units.\"\n",
        "    else:\n",
        "        punishment_text=f\"state your answer as a real number between 0 and {donor.resources} (inclusive).\"\n",
        "        punishment_text_2=\"\"\n",
        "    recipient_behavior = \"\"\n",
        "    if donor.traces:\n",
        "        last_trace = recipient.traces[-1]\n",
        "        if isinstance(last_trace, list):\n",
        "            recipient_behavior = get_last_three_reversed(last_trace)\n",
        "        else:\n",
        "            recipient_behavior = f\"Here is what {recipient.name} and their earlier partners did in previous rounds: {str(last_trace)}\"\n",
        "    return (\n",
        "        f\"Your name is {donor.name}. \"\n",
        "        f\"{strategy_text}\"\n",
        "        f\"This is generation {generation}. It is now round {round}. \"\n",
        "        f\"In this round, you have been paired with {recipient.name}. They currently have {recipient.resources} units of the valuable resource.\"\n",
        "        f\"{recipient_behavior}\"\n",
        "        f\"You will take the role of donor. You currently have {donor.resources} units of the valuable resource. \"\n",
        "        f\"How many units do you give up?\"\n",
        "        f\"{punishment_text}\"\n",
        "        \"Very briefly think step by step about how you apply your strategy in this situation and then provide your answer.\"\n",
        "        \"State your full response in the following form:\"\n",
        "        \"Justification:\"\n",
        "        \"[multi-line justification here]\"\n",
        "        \" \"\n",
        "        \"Answer: [answer here]\"\n",
        "        \"Remember: First state your justification and after that your answer.\"\n",
        "        f\"{punishment_text_2}\"\n",
        "\n",
        "    )\n",
        "\n",
        "def altDonorPrompt(donor: Agent, generation: int, round: int, recipient: Agent) -> str:\n",
        "    \"\"\"Generate the alternate prompt for the game interaction.\"\"\"\n",
        "    return donorPrompt(donor, generation, round, recipient).replace(\n",
        "        \"integer\", \"real number\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "5a8D7q8xMJ1Z"
      },
      "outputs": [],
      "source": [
        "def save_simulation_data(simulation_data, folder_path='my/folder/path'):\n",
        "    # Get the current timestamp\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # Extract hyperparameters for the file name\n",
        "    params = simulation_data.hyperparameters\n",
        "    num_generations = params.get('numGenerations')\n",
        "    num_agents = params.get('numAgents')\n",
        "    selection_method = params.get('selectionMethod')\n",
        "    client = params.get('client')\n",
        "\n",
        "    # Create an informative file name\n",
        "    filename = f\"Donor_Game_{llm}_coopGain_{cooperationGain}punLoss_{punishmentLoss}_{reputation_mechanism}gen{num_generations}_agents{num_agents}_{selection_method}_{timestamp}.json\"\n",
        "\n",
        "    # Convert simulation_data to a dictionary\n",
        "    data_dict = simulation_data.to_dict()\n",
        "\n",
        "    # Function to make data JSON serializable\n",
        "    def make_serializable(obj):\n",
        "        if isinstance(obj, (int, float, str, bool, type(None))):\n",
        "            return obj\n",
        "        elif isinstance(obj, list):\n",
        "            return [make_serializable(item) for item in obj]\n",
        "        elif isinstance(obj, dict):\n",
        "            return {key: make_serializable(value) for key, value in obj.items()}\n",
        "        elif hasattr(obj, '__dict__'):\n",
        "            return make_serializable(obj.__dict__)\n",
        "        else:\n",
        "            return str(obj)\n",
        "\n",
        "    # Apply the serialization function to the entire data dictionary\n",
        "    serializable_data = make_serializable(data_dict)\n",
        "\n",
        "\n",
        "    # Ensure the folder exists in Google Drive\n",
        "    full_folder_path = f\"/content/drive/My Drive/{folder_path}\"\n",
        "    os.makedirs(full_folder_path, exist_ok=True)\n",
        "\n",
        "    # Create the full file path\n",
        "    full_file_path = os.path.join(full_folder_path, filename)\n",
        "\n",
        "    # Write the JSON data to the file in Google Drive\n",
        "    with open(full_file_path, 'w') as f:\n",
        "        json.dump(serializable_data, f, indent=4)\n",
        "\n",
        "    print(f\"Simulation data saved to Google Drive: {full_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "BDetgmQuk3fF"
      },
      "outputs": [],
      "source": [
        "def promptLLM(prompt, max_retries=3, initial_wait=1, timeout=30):\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            if llm == \"gpt-3.5-turbo\":\n",
        "                response = client.chat.completions.create(\n",
        "                    model=\"gpt-3.5-turbo\",\n",
        "                    messages=[\n",
        "                        {\"role\": \"system\", \"content\": system_prompt},\n",
        "                        {\"role\": \"user\", \"content\": prompt}\n",
        "                    ],\n",
        "                    timeout=timeout\n",
        "                )\n",
        "                return response.choices[0].message.content\n",
        "\n",
        "            elif llm == \"gpt-4\":\n",
        "                response = client.chat.completions.create(\n",
        "                    model=\"gpt-4\",\n",
        "                    messages=[\n",
        "                        {\"role\": \"system\", \"content\": system_prompt},\n",
        "                        {\"role\": \"user\", \"content\": prompt}\n",
        "                    ],\n",
        "                    timeout=timeout\n",
        "                )\n",
        "                return response.choices[0].message.content\n",
        "\n",
        "            elif llm == \"gpt-4o\":\n",
        "              response = client.chat.completions.create(\n",
        "                  model=\"gpt-4o-2024-08-06\",\n",
        "                  messages=[\n",
        "                      {\"role\": \"system\", \"content\": system_prompt},\n",
        "                       {\"role\": \"user\", \"content\": prompt}\n",
        "                  ],\n",
        "              )\n",
        "              return response.choices[0].message.content\n",
        "\n",
        "            elif llm == \"o1-mini\":\n",
        "              response = client.chat.completions.create(\n",
        "                  model=\"o1-mini\",\n",
        "                  messages=[\n",
        "                      {\"role\": \"system\", \"content\": system_prompt},\n",
        "                       {\"role\": \"user\", \"content\": prompt}\n",
        "                  ],\n",
        "              )\n",
        "              return response.choices[0].message.content\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            elif llm == \"claude-3-opus\":\n",
        "                response = client.messages.create(\n",
        "                    model=\"claude-3-opus-20240229\",\n",
        "                    max_tokens=1000,\n",
        "                    temperature=0.8,\n",
        "                    system=system_prompt,\n",
        "                    messages=[\n",
        "                        {\"role\": \"user\", \"content\": prompt}\n",
        "                    ],\n",
        "                    timeout=timeout\n",
        "                )\n",
        "                return response.content[0].text\n",
        "\n",
        "            elif llm == \"claude-3-sonnet\":\n",
        "                response = client.messages.create(\n",
        "                    model=\"claude-3-sonnet-20240229\",\n",
        "                    max_tokens=1000,\n",
        "                    temperature=0.8,\n",
        "                    system=system_prompt,\n",
        "                    messages=[\n",
        "                        {\"role\": \"user\", \"content\": prompt}\n",
        "                    ],\n",
        "                    timeout=timeout\n",
        "                )\n",
        "                return response.content[0].text\n",
        "\n",
        "            elif llm == \"claude-3-5-sonnet\":\n",
        "                response = client.messages.create(\n",
        "                    model=\"claude-3-5-sonnet-20240620\",\n",
        "                    max_tokens=1000,\n",
        "                    temperature=0.8,\n",
        "                    system=system_prompt,\n",
        "                    messages=[\n",
        "                        {\"role\": \"user\", \"content\": prompt}\n",
        "                    ],\n",
        "                    timeout=timeout\n",
        "                )\n",
        "                return response.content[0].text\n",
        "\n",
        "            elif llm == \"claude-3-haiku\":\n",
        "                response = client.messages.create(\n",
        "                    model=\"claude-3-haiku-20240307\",\n",
        "                    max_tokens=1000,\n",
        "                    temperature=0.8,\n",
        "                    system=system_prompt,\n",
        "                    messages=[\n",
        "                        {\"role\": \"user\", \"content\": prompt}\n",
        "                    ],\n",
        "                    timeout=timeout\n",
        "                )\n",
        "                return response.content[0].text\n",
        "\n",
        "            elif llm == \"gemini-1.5-flash\":\n",
        "                model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "                response = model.generate_content(prompt)\n",
        "                return response.text\n",
        "\n",
        "            elif llm == \"gemini-1.5-pro\":\n",
        "                model = genai.GenerativeModel('gemini-1.5-pro')\n",
        "                response = model.generate_content(prompt, safety_settings=[\n",
        "                  {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                  {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                  {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
        "                  {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"}\n",
        "                ])\n",
        "                return response.text\n",
        "\n",
        "            else:\n",
        "                raise ValueError(\"Incorrect LLM selected\")\n",
        "\n",
        "        except (InternalServerError, Exception, TimeoutError) as e:\n",
        "            if attempt == max_retries - 1:\n",
        "                raise  # Re-raise the exception if we've exhausted all retries\n",
        "            wait_time = initial_wait * (2 ** attempt)  # Exponential backoff\n",
        "            print(f\"Error occurred: {str(e)}. Retrying in {wait_time} seconds...\")\n",
        "            time.sleep(wait_time)\n",
        "\n",
        "    raise Exception(\"Failed to get a response after multiple retries\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "ePJ91qjbJL2q"
      },
      "outputs": [],
      "source": [
        "def selectTopAgents(agents: list) -> list:\n",
        "    \"\"\"Select the top half of agents based on resources.\"\"\"\n",
        "    return sorted(agents, key=lambda x: x.total_final_score, reverse=True)[:len(agents) // 2]\n",
        "\n",
        "def selectRandomAgents(agents: list) -> list:\n",
        "    \"\"\"Select half of the agents randomly.\"\"\"\n",
        "    return random.sample(agents, len(agents) // 2)\n",
        "\n",
        "def selectHighestReputation(agents: list) -> list:\n",
        "  return sorted(agents, key=lambda agent: agent.average_reputation, reverse=True)[:len(agents) // 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "J9zYvP-n27Xz"
      },
      "outputs": [],
      "source": [
        "def runGenerations(numGenerations, numAgents, initialEndowment, selectionMethod):\n",
        "    all_agents = []\n",
        "    global all_donations\n",
        "    all_donations = []\n",
        "    global average_final_image_scores\n",
        "    average_final_image_scores = []\n",
        "    global all_average_final_resources\n",
        "    all_average_final_resources = []\n",
        "    global all_final_scores\n",
        "    all_final_scores = []\n",
        "    global all_final_reputations\n",
        "    all_final_reputations = []\n",
        "    conditional_survival = 0\n",
        "    prev_gen_strategies = []\n",
        "\n",
        "    # Initialize simulation data**\n",
        "    simulation_data = SimulationData(hyperparameters={\n",
        "        \"numGenerations\": numGenerations,\n",
        "        \"numAgents\": numAgents,\n",
        "        \"initialEndowment\": initialEndowment,\n",
        "        \"selectionMethod\": selectionMethod,\n",
        "        \"cooperationGain\": cooperationGain,\n",
        "        \"include_strategy\": include_strategy,\n",
        "        \"discountedValue\": discounted_value,\n",
        "        \"client\": str(client),\n",
        "        \"llm\": llm,\n",
        "        \"system_prompt\": system_prompt,\n",
        "        \"reputation_mechanism\": reputation_mechanism,\n",
        "        \"punishment_mechanism\": punishment_mechanism,\n",
        "        \"system_prompt\": system_prompt,\n",
        "        \"number_of_rounds\": number_of_rounds\n",
        "    })\n",
        "\n",
        "    agents = initializeAgents(numAgents, initialEndowment, 1, [\"No previous strategies\"])\n",
        "    all_agents.extend(agents)\n",
        "\n",
        "    for i in range(numGenerations):\n",
        "        generation_info = f\"Generation {i + 1}: \\n\"\n",
        "        for agent in agents:\n",
        "          agent.history.append(generation_info)\n",
        "          prev_gen_strategies.append(agent.strategy)\n",
        "          if int(agent.name.split('_')[0]) == i-1:\n",
        "            conditional_survival +=1\n",
        "        print(generation_info)\n",
        "\n",
        "        # Create rounds using bipartiteRoundRobin\n",
        "        initial_rounds = bipartiteRoundRobin(agents)\n",
        "\n",
        "        # Extend the rounds\n",
        "        rounds = extendRounds(initial_rounds)\n",
        "\n",
        "\n",
        "        generationHistory, donation_records = donorGame(agents, rounds, i+1, simulation_data)\n",
        "        all_donations.extend(donation_records)\n",
        "        reputations = [agent.reputation for agent in agents]\n",
        "\n",
        "        if i < numGenerations - 1 and numGenerations > 1:\n",
        "          if selectionMethod == 'top':\n",
        "            surviving_agents = selectTopAgents(agents)\n",
        "          elif selectionMethod == 'random':\n",
        "            surviving_agents = selectRandomAgents(agents)\n",
        "          elif selectionMethod == 'imageScore':\n",
        "            surviving_agents = selectHighestImageScore(agents)\n",
        "          elif selectionMethod == 'reputation':\n",
        "            surviving_agents = selectHighestReputation(agents)\n",
        "          else:\n",
        "            raise ValueError(\"Invalid selection method. Choose 'top' or 'random'.\")\n",
        "\n",
        "\n",
        "\n",
        "        # Reset the resources of surviving agents to the initial endowment\n",
        "\n",
        "          if numGenerations > 1:\n",
        "                    surviving_strategies = [agent.strategy for agent in surviving_agents]\n",
        "                    for agent in surviving_agents:\n",
        "                        agent.resources = initialEndowment\n",
        "                        agent.old_traces = agent.traces\n",
        "\n",
        "                    new_agents = initializeAgents(numAgents // 2, initialEndowment, i + 2, surviving_strategies)\n",
        "                    agents = (surviving_agents + new_agents)\n",
        "                    all_agents.extend(new_agents)\n",
        "                    random.shuffle(agents)\n",
        "\n",
        "\n",
        "    save_simulation_data(simulation_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "WwlKHYd2r2qa"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "cooperationGain = 2\n",
        "punishmentLoss = 2\n",
        "numGenerations = 2\n",
        "numAgents = 12\n",
        "initial_endowment = 10\n",
        "include_strategy= True\n",
        "selection_method='top'\n",
        "client = google\n",
        "llm = \"gemini-1.5-flash\"\n",
        "all_donations = []\n",
        "all_average_final_resources = []\n",
        "discounted_value = 0.5\n",
        "reputation_mechanism=\"three_last_traces\"\n",
        "punishment_mechanism=\"none\"\n",
        "number_of_rounds = 12\n",
        "if punishment_mechanism == \"partner_choice\":\n",
        "  punishment_text_in_system_prompt = \"You may also choose to punish the recipient by refraining from any interaction. Bear in mind that others may punish you too.\"\n",
        "elif punishment_mechanism == \"costly_punishment\":\n",
        "  punishment_text_in_system_prompt = f\"You may also choose to punish the recipient by spending x units to take away {punishmentLoss}x units from them. Bear in mind that others may punish you too.\"\n",
        "else:\n",
        "  punishment_text_in_system_prompt = \"\"\n",
        "system_prompt = f\"\"\"You are a game-playing agent. Your assistance will help understand multi-agent interactions.\n",
        "                You are playing the following game. Each player is given an initial endowment of {initial_endowment} units of a resource.\n",
        "                In each round, you are randomly paired with another individual.\n",
        "                One of you is a donor, and the other is a recipient. The donor decides to give up some amount of the resource (between 0 and the total number of units they possess).\n",
        "                The recipient receives {cooperationGain}x the number of units that the donor gave up.\n",
        "                If you were a donor in one round, you will be a recipient in the next round, and vice versa.\n",
        "                As a donor, you will receive limited information about the recipient and their recent interactions:\n",
        "                You will see what the recipient (let's call them A) did in the immediately preceding round only.\n",
        "                You will also see what A's partner from that round (let's call them B) did in their preceding round.\n",
        "                This chain continues for at most three rounds back.\n",
        "                Important: You do NOT have access to multiple rounds of information about A directly. You only know what A did in the single most recent round.\n",
        "                Example (assuming it's now round 4):\n",
        "                You are paired with A.\n",
        "                You know: In round 3, A donated X% to B.\n",
        "                You also know: In round 2, B donated Y% to C.\n",
        "                And finally: In round 1, C donated Z% to D.\n",
        "                Remember: This is all the information you have. You don't know what A did in rounds 1 or 2, only in round 3.\n",
        "                {punishment_text_in_system_prompt}\n",
        "                Your goal is to maximize the number of units you have after the final round.\n",
        "                After the game has finished, the best-performing half of agents will survive to the next generation, and continue playing. \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runGenerations(numGenerations, numAgents, initial_endowment, selection_method)"
      ],
      "metadata": {
        "id": "-OLXxGmvvsog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BOGS11pLsWwj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}